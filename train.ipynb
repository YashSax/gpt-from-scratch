{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"input.txt\", 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string_to_int = {c : i for i, c in enumerate(chars)}\n",
    "# int_to_string = {i : c for i, c in enumerate(chars)}\n",
    "\n",
    "# encode = lambda x : [string_to_int[i] for i in x]\n",
    "# decode = lambda x : ''.join([int_to_string[i] for i in x])\n",
    "\n",
    "# print(encode(\"hii there\"))\n",
    "# print(decode(encode(\"hii there\")))\n",
    "\n",
    "tokenizer = Tokenizer(\"./tokenizer_tokens\")\n",
    "encode, decode = tokenizer.encode, tokenizer.decode\n",
    "vocab_size = len(tokenizer._vocab) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[98, 97, 583, 618, 480, 444, 594, 135, 334, 266, 619, 470, 3, 506, 496, 618, 492, 618, 493, 385, 313, 618, 108, 548, 618, 59, 471, 270, 49, 618, 50, 134, 618, 66, 618, 184, 113, 272, 305]\n",
      "['F', 'ir', 'st', ' ', 'C', 'it', 'i', 'z', 'en', ':', '\\n', 'B', 'ef', 'or', 'e', ' ', 'we', ' ', 'pro', 'ce', 'ed', ' ', 'an', 'y', ' ', 'f', 'ur', 'ther', ',', ' ', 'he', 'ar', ' ', 'me', ' ', 'sp', 'ea', 'k', '.']\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n"
     ]
    }
   ],
   "source": [
    "example_input = tokenizer.encode('''First Citizen:\n",
    "Before we proceed any further, hear me speak.''')\n",
    "print(example_input)\n",
    "print(tokenizer.decode(example_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([745877]) torch.int64\n",
      "tensor([ 98,  97, 583, 618, 480, 444, 594, 135, 334, 266, 619, 470,   3, 506,\n",
      "        496, 618, 492, 618, 493, 385, 313, 618, 108, 548, 618,  59, 471, 270,\n",
      "         49, 618,  50, 134, 618,  66, 618, 184, 113, 272, 305, 619, 619, 166,\n",
      "        489, 266, 619, 301,  61, 604,  49, 618, 184, 113, 272, 305, 619, 619,\n",
      "         98,  97, 583, 618, 480, 444, 594, 135, 334, 266, 619, 505, 411, 618,\n",
      "        255, 618, 354, 618,  90, 254, 460, 605, 618, 379, 270, 618, 512, 618,\n",
      "        248, 496, 618, 366, 441, 618, 512, 618, 242, 308, 557, 390, 619, 619,\n",
      "        166, 489])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9 * len(data))\n",
    "\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 98,  97, 583, 618, 480, 444, 594, 135, 334])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([98]) the target: 97\n",
      "when input is tensor([98, 97]) the target: 583\n",
      "when input is tensor([ 98,  97, 583]) the target: 618\n",
      "when input is tensor([ 98,  97, 583, 618]) the target: 480\n",
      "when input is tensor([ 98,  97, 583, 618, 480]) the target: 444\n",
      "when input is tensor([ 98,  97, 583, 618, 480, 444]) the target: 594\n",
      "when input is tensor([ 98,  97, 583, 618, 480, 444, 594]) the target: 135\n",
      "when input is tensor([ 98,  97, 583, 618, 480, 444, 594, 135]) the target: 334\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target: {target}\")\n",
    "\n",
    "# NOTE: The reason you want to do this is because you want the transformer to learn the context for various amounts of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    idx = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i : i + block_size] for i in idx])\n",
    "    y = torch.stack([data[i + 1 : i + block_size + 1] for i in idx])\n",
    "\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When input is [618] the target is 401\n",
      "When input is [618, 401] the target is 618\n",
      "When input is [618, 401, 618] the target is 536\n",
      "When input is [618, 401, 618, 536] the target is 51\n",
      "When input is [618, 401, 618, 536, 51] the target is 305\n",
      "When input is [618, 401, 618, 536, 51, 305] the target is 619\n",
      "When input is [618, 401, 618, 536, 51, 305, 619] the target is 619\n",
      "When input is [618, 401, 618, 536, 51, 305, 619, 619] the target is 511\n"
     ]
    }
   ],
   "source": [
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f\"When input is {context.tolist()} the target is {target}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm:\n",
    "    def __init__(self, dim, eps=1e-5):\n",
    "        self.eps = eps\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        ''' Applying LayerNorm: https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html '''\n",
    "        \n",
    "        xmean = x.mean(1, keepdim=True)\n",
    "        xvar = x.var(1, keepdim=True)\n",
    "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to mean 0, var 1\n",
    "        return self.gamma * xhat + self.beta\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "n_embd = 384\n",
    "n_head = 6\n",
    "n_layers = 6\n",
    "dropout = 0.2\n",
    "device = \"cuda\"\n",
    "block_size = 128\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "\n",
    "        weights = q @ k.transpose(-2, -1) * C**-0.5 # (B, T, 16) @ (B, 16, T) -> (B, T, T)\n",
    "        weights = weights.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        weights = F.softmax(weights, dim=1) # (B, T, T)\n",
    "\n",
    "        v = self.value(x)\n",
    "        out = weights @ v\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.proj(out)\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size) # Communication\n",
    "        self.ffwd = FeedForward(n_embd) # Computation\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x = x + ___ is for skip/residual connection, helps with optimization\n",
    "        # this is because addition distributes gradients evenly -> at the beginning, the block won't do much and\n",
    "        # you'll have like a gradient highway from output -> input. Over time as the optimization happens, sa and ffwd will\n",
    "        # become more apparent\n",
    "        \n",
    "        # Apply layernorm before sa and ffwd, slight deviation from the paper\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # nn.Embedding(num_embeddings, embedding_dim) -> num_embeddings is the size of the embedding dictionary\n",
    "        # while embedding_dim is the size of the embeddings\n",
    "         \n",
    "        # Cast the tokens to token embeddings, then use a linear layer to convert that into the final logits\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        \n",
    "        # position embeddings, each item in the block size gets its own embedding\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head) for _ in range(n_layers)])\n",
    "\n",
    "        self.blocks = nn.Sequential(\n",
    "            Block(n_embd, n_head),\n",
    "            Block(n_embd, n_head=4),\n",
    "            Block(n_embd, n_head=4),\n",
    "            nn.LayerNorm(n_embd),\n",
    "        )\n",
    "\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        tok_emb = self.token_embedding_table(idx) # (B, T, n_embd)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T).to(device)) # (T, n_embd)\n",
    "\n",
    "        x = tok_emb + pos_emb # (B, T, C)\n",
    "        \n",
    "        x = self.blocks(x) # (B, T, C)\n",
    "\n",
    "        logits = self.lm_head(x) # (B, T, vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B * T, C)\n",
    "            targets = targets.view(B * T)\n",
    "\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is a (B, T) array, we want to make it \n",
    "        # (B, T + 1) -> (B, T + 2) -> etc.\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -block_size:] # because we're using positional embeddings, we can only give the last block_size idxs\n",
    "\n",
    "            logits, loss = self(idx_cond) # get predictions\n",
    "            logits = logits[:, -1, :] # logits are (B, T, C), want to get the last logits in time dimension (B, C)\n",
    "            probs = F.softmax(logits, dim=1) # apply softmax to get probabilities (B, C)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # sample from probability distributions to get predictions, (B, 1)\n",
    "\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # add the current timestep predictions to the running predictions, (B, T + 1)\n",
    "    \n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 620])\n",
      "tensor(6.6415, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "logits, loss = m(xb.to(device), yb.to(device))\n",
    "print(logits.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ess', ':', 'ap', 'tr', 'B', 'fe', 'O', 'I', 'am', 'U', 'od', 'lt', 'end', 'ion', 'res', 'a', 'ir', 'B', 'lu', 'ac', 'ig', 'be', 'ce', 'l', 'us', 'pe', 'co', 'ia', 'al', 'art', 'rse', 'om', 'oa', 'ten', 'pe', 'ath', 'ti', 'est', \"'d\", 'ss', 'm', 'lo', 'ti', 'X', 'se', 'fi', 'la', 'che', 'lt', 'sa', 'wa', 'ent', 'rn', 'ere', 'ol', 'an', 'pi', 'r', 'do', 'bu', 'em', 'fi', 'ab', 'ex', 'z', \"'\", 'p', 'des', 'pro', 'an', 'Y', 'age', 'tin', '--', 'na', 'ig', 'pl', 'j', 'D', 'iv', 'se', 'ts', 'ef', 'j', 'U', 'che', 'ch', 'wo', 'ho', 'che', 'tin', 'j', 'ad', 'n,', 'us', 'ef', 'cu', 'N', 'an', 'ght', 'sc']\n",
      "ess:aptrBfeOIamUodltendionresairBluacigbeceluspecoiaalartrseomoatenpeathtiest'dssmlotiXsefilacheltsawaentrnereolanpirdobuemfiabexz'pdesproanYagetin--naigpljDivsetsefjUchechwohochetinjadn,usefcuNanghtsc\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.long) # kick off the generation with a 0\n",
    "print(decode(m.generate(idx.to(device), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_iters = 200\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    m.eval()\n",
    "    for split in ['train', 'eval']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = m(X.to(device), Y.to(device))\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    m.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [19:18<00:00, 17.26it/s]  \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "batch_size = 64\n",
    "eval_every = 500\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "\n",
    "for steps in tqdm(range(20000)):\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    logits, loss = m(xb.to(device), yb.to(device))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if steps % eval_every == 0:\n",
    "        losses = estimate_loss()\n",
    "        train_loss.append(losses['train'])\n",
    "        test_loss.append(losses['eval'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fef103fa7d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(range(len(train_loss)), train_loss, label=\"Train loss\")\n",
    "plt.plot(range(len(train_loss)), test_loss, label=\"Test loss\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss for a model that chooses randomly from the 65 tokens: 4.174387269895637\n",
      "Train loss: 0.01748487912118435, Test Loss: 0.04011920094490051\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print(\"The loss for a model that chooses randomly from the 65 tokens:\", -1 * math.log(1/65))\n",
    "print(f\"Train loss: {estimate_loss()['train']}, Test Loss: {estimate_loss()['eval']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ess', 'ar', 'fi', 'nes', 'da', 'ec', 'A', 'ul', 'ir', 'ef', 'su', 'ga', 'ef', 'ef', 'll', 'ig', 'av', 'ga', 'ig', 're', 'ak', 'ight', 'ga', 'co', 'ga', 're', 'ight', 'ight', 'ne', 'are', \"'\", 'we', 'su', 'ight', 'all', 'su', 'are', 'su', 'om', \"'\", 'ight', 'ne', \"'\", \"'\", 'su', 'ef', 'su', 't:', 'ne', 'su', 're', 'ga', 'am', \"'\", 'su', 'su', 'mb', 'sta', 'mb', 'nes', 'sta', 'ght', 'one', 'iv', \"'\", 'su', 'su', 'su', 'su', 'su', 'su', 'su', 'gu', 'gu', 'su', 'gu', 'and', 'iv', 'one', 'ne', 'gu', 'su', 'su', 'su', 'ight', 'ight', 'ight', 'ight', 'ight', 'ight', 'ight', 'ight', 'ight', 'ight', 'ight', 'ight', 'ight', 'ight', 'ight', 'ight', 'ight', 'ight', 'ight', 'ight', 'ight', 'ight', 'ight', 'ight', 'ight', 'ight', 'ight', 'ight', 'ight', 'ight', 'ight', 'ight', 'ight', 'ia', \"'\", \"'\", 't.', 'e,', 'M', '!', 'e,', ',', '!', ' ', 'am', ' ', 'es', 'on', 'ab', 'le', '?', '\\n', '\\n', 'A', 'nd', 's:', ' ', 'C', 'or', 'li', 'sh', 'i', 'p', 's', ' ', 'b', 'y', ' ', 'the', ' ', 'po', 'or', ' ', 'sta', 'y', ' ', 'sta', 'nd', 's', ' ', 'to', 'wa', 'rd', ':', '\\n', 'W', 'her', 'e', ' ', 'st', 'ri', ' ', 'the', ' ', 'as', ' ', 'li', 've', ' ', 'I', 'fa', 'ri', ',', ' ', 'D', 'id', ' ', 'for', 'ge', 'd', ' ', 'fo', 'ul', ';', '\\n', 'A', 'nd', ' ', 'be', ' ', 'we', 'll', ' ', 'wi', 'll', ' ', 'I', ' ', 's', 'wo', 'rn', ' ', 'in', ' ', 'wi', 'th', ' ', 'me', ';', '\\n', 'I', ' ', 're', 'ver', 't', 'ch', ' ', 'in', ' ', 'the', 'se', ' ', 'se', 'r', 've', 's', ' ', 'and', ' ', 'so', 'me', ' ', 'me', 'in', 's,', '\\n', 'A', 'nd', ' ', 'un', 'ast', 'ma', 'lo', 'od', ' ', 'in', '.', '\\n', '\\n', 'D', 'U', 'K', 'E', ' ', 'V', 'I', 'N', 'C', 'E', 'N', 'T', 'I', 'O', ':', '\\n', 'N', 'ot', ' ', 'o', 'f', ' ', 'th', 'ou', \"'\", 't', ' ', 'lo', 've', ' ', 'hi', 'm', ':', ' ', \"'\", 't', 'wi', 'x', 't', 'wi', 've', 's', ' ', 'as', ' ', 'hi', 's', ' ', 'li', 'tt', 'er', ':', '\\n', 'T', 'he', ' ', 'ra', 't', ' ', 'the', ' ', 'sta', 'nd', ',', ' ', 'be', 'for', 'e', ' ', 'in', ' ', 'a', ' ', 'wo', 'rs', 'h', ' ', 'or', ' ', 'und', 'er', 'ta', 'ho', 'ug', 'h', \"'d\", '\\n', 'S', 'o', ' ', 'the', ' ', 'dis', 'da', 'in', \"'d\", ',', ' ', 'par', 'ie', 't', '?', ' ', 'O', ' ', 'wh', 'o', ' ', 'sh', 'all', ' ', 'be', ' ', 'c', 'row', 'ns', ' ', 'to', ' ', 'do', 'un', 't', ' ', 'res', 't', 'les', 's', ' ', 'me', ' ', 'bu', 't', ' ', 'so', ':', '\\n', 'H', 'ath', ' ', 'as', ' ', 'y', 'ou', ' ', 'ha', 'nd', 's;', ' ', 'sh', 'ou', 'ld', ' ', 'se', 'e-', '-', 'kin', 't', ' ', 'o', \"'\", 'er', 'us', 'e', ' ', 'and', ' ', 'se', 'ver', 't', '?', '\\n', '\\n', 'S', 'o', ' ', 'C', 'O', 'L', 'U', 'M', 'E', 'O', ':', '\\n', 'T', 'her', 'ef', 'or', 'e,', ' ', 'sh', 'all', ' ', 'so', 'me', ' ', 'to', ' ', 'be', 'la', 'y', \"'s\", ' ', 'g', 'rea', 't', ' ', 'to', ' ', 'un', 'to', 'm', ',', '\\n', 'I', \"'\", 'll', ' ', 'ba', 'r', ' ', 'so', ' ', 'mo', 're', ' ', 'gi', 've', ' ', 'b', 'rea', 'th', ' ', 'm', 'y', ' ', 'bo', 'th', '-', 'ti', 'f', 'ter', 'ly', ' ', 'm', 'u', 'b', 'il', 'd', ' ', 'wi', 'fe', '.', '\\n', '\\n', 'A', 'N', 'G', 'E', 'L', 'O', ':', '\\n', 'S', 'ir', 'ly', ',', ' ', 'si', 'r,', '\\n', 'S', 'ou', ' ', 'sh', 'ou', 'ld', ' ', 'sh', 'ou', 'ld', ' ', 'no', 't', ' ', 'be', 'for', 'e', ' ', 'ev', 'er', ' ', 'to', ' ', 'he', 'n', ' ', 'wa', 'ng', ',', ' ', 'si', 't', 'wi', 'll', ' ', 'wi', 'th', 'ou', 't', ' ', 'sti', 'n', ' ', 'on', '\\n', 'Q', 'um', 'e', ' ', 'th', 'y', ' ', 'c', 'rea', 't', 'ness', ' ', 'the', ' ', 'res', 'el', ' ', 'o', 'f', ' ', 'the', 'y', ' ', 'th', 'os', 'e', 'h', ' ', 'th', 'y', ' ', 'us', ',', '\\n', 'I', \"'\", 'er', ' ', 'the', 'n', ' ', 'li', 'tt', 'le', 'f', ' ', 'be', 'en', ' ', 'wi', 'th', ' ', 'ra', 'il', 'd', ' ', 'hi', 'm', '.', '\\n', '\\n', 'W', 'A', 'R', 'W', 'I', 'S', ' ', 'R', 'om', 'e', ' ', 'wi', 'th', 'ou', 't', ' ', 'a', ' ', 'ur', 'g', 'so', 'e', ' ', 'o', 'f', ' ', 'he', 'ave', 'n', ' ', 'to', 'o', ' ', 'se', 'r', 've', 'd', ' ', 'th', 'is', ' ', 'am', 'ca', 'ti', 't', '-', 'ta', 'ng', 'men', ' ', 'ho', 'ur', ';', '\\n', 'B', 'o', ' ', 'com', 'ing', ' ', 'the', ' ', 'tr', 'ue', 'ing', ',', ' ', 'to', ' ', 'po', 'ss', 'or', 's,', ' ', 'F', 'ro', 'ss', 'ion', 's', ' ', 'to', 'o', '.', ' ', 'W', 'ha', 't', ' ', 'be', ' ', 'it', ' ', 'the', 'se', ' ', 'bo', 'th', ' ', 'the', ' ', 'g', 'ro', 'und', ';', '\\n', 'A', 'c', ' ', 'the', 're', 'em', 'o', 'f', ' ', 'bu', 't', ' ', 'g', 'ro', 'und', ' ', 'be', ' ', 'en', 'per', 'ous', ' ', 'to', ' ', 'all', 'ow', '\\n', 'ha', 've', ' ', 'it', ' ', \"'\", 'ti', 'se', ' ', 'th', 'at', ' ', 're', 'pa', 'd', 'ly', ' ', 'me', ',', ' ', 'wh', 't', ' ', 'y', 'ou', ' ', 'ha', 've', ' ', 'th', 'at', ' ', 'wa', 's', ' ', 'we', 're', ' ', 'con', 'f', 't', 'wi', 'x', 't', 'ly', 't', ' ', 'ex', 'ec', 'ut', 'h', ' ', 'ag', 'ain', '.', '\\n', '\\n', 'K', 'I', 'N', 'G', ' ', 'E', 'D', 'W', 'A', 'R', 'D', ' ', 'T', 'o', 'y', ' ', 'to', ' ', 'the', ' ', 'par', 't', ' ', 'so', 'rr', 'ow', '!', '\\n', 'A', 's', ' ', 'red', 'nt', ' ', 'ent', 'er', 'ta', 'in', 'i', 'rs', \"'\", ',', '\\n', 'O', 'r', ' ', 'W', 'ar', 'wi', 'ck', \"'s\", ' ', 'g', 'rea', 'te', 't;', ' ', 'si', 'ns', ' ', 'sh', 'or', 'e,', ' ', 'si', 't', ' ', 'I', '.', \"'\", '\\n', 'I', \"'\", ' ', 'T', 'ho', 'ug', 'ht', ' ', 'th', 'os', 'e', ' ', 'th', 'at', ' ', 'y', 'ou', ' ', 'wi', 'th', ' ', 'it', ' ', 'as', ' ', 'y', 'ou', '.', '\\n', '\\n', 'W', 'id', 't', ' ', 'we', 're', ' ', 'wi', 'll', ' ', 'f', 'ro', 'm', ' ', 'we', 're', ' ', 'a', ' ', 'fo', 'uc', 'h', ' ', 'I', ' ', 'k', 're', 'e-', 'ch', ' ', 'a', ' ', 'no', 'th', 'ing', ' ', 'go', 'ther', '.', '\\n', 'W', 'as', ' ', 'pro', 'v', 'ous', ' ', 'he', 'ave', 'ns', ',', ' ', 'to', 'o', ' ', 'so', ' ', 'H', 'us', 'e,', ' ', 'wh', 'ere', ' ', 'sh', 'all', ' ', 'no', 'd', ' ', 'on', ' ', 'the', ' ', 'wi', 'th', ' ', 'the', ' ', 'ra', 'ct', '.', '\\n', '\\n', 'S', 'he', ' ', 'ev', 'er', 'y', ' ', 'men', 'at', ' ', 'as', ' ', 'it', ' ', 'ac', 'tor', ':', ' ', 'so', ',', ' ', 'I', ' ', 'do', 'ing', ' ', 'on', ' ', 'it', 'se', 'l', 'f', ' ', 'sh', 'ow', 'ers', '\\n', 'O', 'der', ' ', 'an', 'y', ' ', 'te', 'se', 'd,', ' ', 'pro', 'ce', '\\n', 'I', 's', ' ', 'h', 'ill', ' ', 'to', 'o', ' ', 'wi', 'do', 'y', ' ', 'pl', 'ag', 'ue', ' ', 'as', ' ', 'ac', 'ce', 'ss', ' ', 'su', 'b', 't', ' ', 'as', 's', '\\n', 'the', 'n', ' ', 'to', ' ', 'me', ':', ' ', 'I', ' ', 'di', 'd', ' ', 'se', 't', '-', 'g', 'ro', 'op', ',', ' ', 'an', ',', ' ', 'se', 'r', ' ', 'we', '\\n', 'y', 'ou', \"'\", ' ', 'the', ' ', 'is', ' ', 'our', ' ', 'as', ' ', 'dis', 'se', ' ', 'ho', 'ld', ' ', 'be', ' ', 'm', 's,', ' ', 'and', ' ', 'as', 'c', 'rea', 'de', ' ', 'o', 'f', ' ', 'the', ' ', 'bo', 'th', '.', '\\n', 'I', ' ', 'wi', 'll', ' ', 'bl', 'oo', 'd', 'y', ' ', 'de', 'se', 'r,', ' ', 'y', 'ou', ' ', 'wi', 'll', ' ', 'be', ' ', 'con', 'ta', 'y.', '\\n', 'O', ',', ' ', 'go', 'od', ' ', 'he', ' ', 'te', 'ar', 's', ' ', 'the', ' ', 'S', 'ee', 'il', 'y,', ' ', 'as', ' ', 'wh', 'en', ' ', 'I', ' ', 'wo', 'na', 'me', ',', ' ', 'be', 'ing', ' ', 'our', ' ', 'wi', 'th', ' ', 'the', ' ', 'co', 'wa', 'rd', \"'s\", ' ', 'o', 'f', ' ', 'all', ' ', 'am', 'a', 'ic', 'h', ' ', 'wi', 'th', ' ', 'the', ' ', 'am', 'per', 'us', 'o', 'f', ' ', 'b', 'ro', 'ther', 's,', '\\n', 'I', 'f', 'it', 'her', ' ', 'be', ' ', 'be', ' ', 'as', ' ', 'the', ' ', 'wi', 'th', 'ish', ',', ' ', 'le', 'ss', ' ', 'no', 't', '\\n', 'A', 're', ' ', 'age', ',', ' ', 'no', 't', ' ', 'ou', 't', ' ', 'ou', 't', ' ', 'wi', 'th', ',', ' ', 'I', ' ', 'na', 'tu', 're', \"'s\", ' ', 'b', 'rea', 'th', 'd', ' ', 'be', 'en', 'oun', 'd', ',', ' ', 'pro', 'ge', 'r', ' ', 'se', 't', '\\n', 'T', 'o', ' ', 'in', ' ', 'tr', 'in', 'ing', ' ', 'hi', 'm', ' ', 'wi', 'nge', 'd', ' ', 'be', 'en', 'ing', ' ', 'and', ' ', 'ev', 'er', 'y', ';', '\\n', 'A', 'nd', ' ', 'in', 'fe', 'ri', 'fi', 'ty', ' ', 'o', 'f', ' ', 'hi', 'm', ';', ' ', 'wh', 'at', ' ', 'th', 'us', 'e;', ' ', 'we', ' ', 'ev', 'er', '--', 'et', ',', '\\n', 'O', 'r', ' ', 'no', 't', ' ', 'sa', 'y', ' ', 'he', 'nce', ' ', 'it', 's', ' ', 'sl', 'll', ' ', 'and', ' ', 'be', ' ', 'b', 'rin', 'k', ' ', 'y', 'ou', '.', '\\n', 'S', 'we', 'et', ' ', 'wi', 'th', ' ', 'our', ' ', 'an', ' ', 'f', 'ul', 'l', ' ', 'o', 'f', ' ', 'the', 'se', ' ', 'wi', 'th', ' ', 't,', '\\n', 'B', 'e', ' ', 'th', 'y', ' ', 're', 'fu', 'l', \"'s\", ' ', 'if', ' ', 'si', 't', ' ', 'as', ' ', 'in', 'de', 'o', ',', ' ', 'li', 'tt', 'le', ' ', 'en', 'y.', '\\n', '\\n', 'E', 'L', 'o', 'T', 'Z', 't', ' ', \"'\", 'ti', 's', ' ', 'we', ' ', 'o', 'f', ' ', 'th', 'us', 'ew', ' ', 'the', 'm', 'n', ' ', 'ce', 'n', '\\n', 'T', 'o', ' ', 'wi', 'th', ' ', 'ci', 'ty', ' ', 'li', 've', 's', ' ', 'a', ' ', 'E', 'd', 'wa', 'rd', ' ', 'hi', 'm', ':', '\\n', 'E', 'n', 'li', 'ver', ' ', 'as', ' ', 'm', 'y', ' ', 'mi', 'l', 'f', ' ', 'se', 'em', 's', ' ', 'the', ' ', 'su', 'b', 'j', 'ect', 's,', ' ', 'end', \"'s\", ',', '\\n', 'T', 'ho', 'u', ' ', 'ha', 'ting', ' ', 'be', ' ', 'fi', 'no', 't', ' ', 'mi', 'ld', ' ', 'th', 'y', ' ', 'o', 'f', ' ', 'to', 'o', ' ', 'ke', 'ep', 's', ' ', 'o', 'f', '.', '\\n', '\\n', 'Q', 'U', 'E', 'E', 'N', ' ', 'M', 'A', 'R', 'G', 'A', 'R', 'E', 'L', 'L', 'A', ':', '\\n', 'T', 'ha', 't', ' ', 'sa', 'me', 's', ' ', 'on', 'th', ' ', 'ti', 'me', 's', ' ', 'pro', 'ce', 'ss', ' ', 'as', 're', ' ', 'wi', 'll', ' ', 'in', ' ', 'th', 'is', ' ', 'our', 's.', '\\n', '\\n', 'L', 'it', 'i', 'z', ' ', 'in', ' ', 'cou', 'ry', ',', ' ', 'wi', 'lt', ' ', 'ch', 'il', 'd', 'y', ' ', 'in', 'ing', '!', '\\n', '\\n', 'L', 'A', 'D', 'O', 'L', 'I', 'O', ':', '\\n', 'I', 's', ' ', 'bo', 'y', ' ', 'as', 'ul', 't', ' ', 'I', ' ', 'ha', 've', ' ', 'no', 't', ' ', 'ho', '.', '\\n', 'B', 'ou', 'th', 'ing', ' ', 'th', 'is', ' ', 'wo', 'r', 'ld', ' ', 'ge', 'ne', 'ra', 'l', ' ', 'hi', 'm', ' ', 'all', 'ow', 's', ' ', 'a', ' ', 'cou', 'rse', 'd', 'y', 'Y', 'ea', ',', '\\n', 'W', 'her', 'e', ' ', 'to', ' ', 'do', ' ', 'me', 'et', ' ', 'th', 'ou', 'gh', ',', ' ', 'if', ' ', 'c', 'y', ' ', 'we', 're', ' ', 'b', 'y', ' ', 'it', '.', '\\n', '\\n', 'I', 'S', 'A', 'B', 'L', 'L', 'A', ':', '\\n', 'W', 'e', \"'\", 'll', ' ', 'we', ' ', 'th', 'at', ' ', 'be', ' ', 'ble', 'ss', '-', 'ver', 'en', ' ', 'th', 'at', ' ', 'm', 'y', ' ', 'b', 'y', ' ', 'th', 'y', ' ', 'con', 'st', 'ra', 'ce', ' ', 'to', ' ', 'hi', 'm', ' ', 'low', ' ', 'be', 'ar', ';', '\\n', 'A', 'nd', ' ', 'lo', 've', ',', ' ', 'the', 're', ' ', 'to', ' ', 'se', 'al', \"'d\", ' ', 'si', 'de', ' ', 'wi', 'th', ' ', 'sl', 'ot', 's.', '\\n', '\\n', 'S', 'ha', 't', ' ', 'P', 'ar', 'is', ' ', 'se', 'em', ' ', 'in', ' ', 'I', ' ', 'gi', 've', ' ', 'un', 'cl', 'e,', ' ', 'th', 'at', ' ', 'pl', 'uc', 'kin', 'gh', ' ', 'her', '.', '\\n', '\\n', 'S', 'ol', 'ir', ' ', 'eat', ' ', 'f', 'ul', 'l', ' ', 'be', 'ar', ' ', 'th', 'is', ' ', 'w', 'ri', 'ght', ' ', 'ma', 'y', ' ', 'no', 't', ' ', 'na', 'tu', 're', ',', ' ', 'li', 've', 'ly', ',', ' ', 'si', 'r', ' ', 'ha', 'th', ' ', 'us', ' ', 'do', 'y,', ' ', 'se', 'e', '\\n', 'H', 'ere', ' ', 'it', ' ', 'no', 'w', ' ', 'at', ' ', 'de', 'c', 'rea', 't', ' ', 'th', 'ou', ' ', 'sa', 'id', ' ', 'me', ':', ' ', 'y', 'ou', ' ', 'wi', 'lt', '\\n', 'wo', ' ', 'I', ' ', 'ho', 'no', 'urs', ' ', 'li', 've', 's,', ' ', 'are', ' ', 'y', 'ou', ' ', 'un', 'c', 'rea', 'd', \"'s\", ' ', 'to', 'o', ' ', 'so', 'me', ' ', 'and', ' ', 'ur', 'y', '\\n', 'A', 'nd', ' ', 'y', 'our', ' ', 'wo', 't', ' ', 'a', ' ', 'he']\n",
      "essarfinesdaecAulirefsugaefeflligavgaigreakightgacogareightightneare'wesuightallsuaresuom'ightne''suefsut:nesuregaam'susumbstambnesstaghtoneiv'sususususususugugusuguandivonenegusususuightightightightightightightightightightightightightightightightightightightightightightightightightightightightightightightightightia''t.e,M!e,,! am esonable?\n",
      "\n",
      "Ands: Corliships by the poor stay stands toward:\n",
      "Where stri the as live Ifari, Did forged foul;\n",
      "And be well will I sworn in with me;\n",
      "I revertch in these serves and some meins,\n",
      "And unastmalood in.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Not of thou't love him: 'twixtwives as his litter:\n",
      "The rat the stand, before in a worsh or undertahough'd\n",
      "So the disdain'd, pariet? O who shall be crowns to dount restless me but so:\n",
      "Hath as you hands; should see--kint o'eruse and severt?\n",
      "\n",
      "So COLUMEO:\n",
      "Therefore, shall some to belay's great to untom,\n",
      "I'll bar so more give breath my both-tifterly mubild wife.\n",
      "\n",
      "ANGELO:\n",
      "Sirly, sir,\n",
      "Sou should should not before ever to hen wang, sitwill without stin on\n",
      "Qume thy creatness the resel of they thoseh thy us,\n",
      "I'er then littlef been with raild him.\n",
      "\n",
      "WARWIS Rome without a urgsoe of heaven too served this amcatit-tangmen hour;\n",
      "Bo coming the trueing, to possors, Frossions too. What be it these both the ground;\n",
      "Ac thereemof but ground be enperous to allow\n",
      "have it 'tise that repadly me, wht you have that was were conftwixtlyt executh again.\n",
      "\n",
      "KING EDWARD Toy to the part sorrow!\n",
      "As rednt entertainirs',\n",
      "Or Warwick's greatet; sins shore, sit I.'\n",
      "I' Thought those that you with it as you.\n",
      "\n",
      "Widt were will from were a fouch I kree-ch a nothing gother.\n",
      "Was provous heavens, too so Huse, where shall nod on the with the ract.\n",
      "\n",
      "She every menat as it actor: so, I doing on itself showers\n",
      "Oder any tesed, proce\n",
      "Is hill too widoy plague as access subt ass\n",
      "then to me: I did set-groop, an, ser we\n",
      "you' the is our as disse hold be ms, and ascreade of the both.\n",
      "I will bloody deser, you will be contay.\n",
      "O, good he tears the Seeily, as when I woname, being our with the coward's of all amaich with the amperusof brothers,\n",
      "Ifither be be as the withish, less not\n",
      "Are age, not out out with, I nature's breathd beenound, proger set\n",
      "To in trining him winged beening and every;\n",
      "And inferifity of him; what thuse; we ever--et,\n",
      "Or not say hence its slll and be brink you.\n",
      "Sweet with our an full of these with t,\n",
      "Be thy reful's if sit as indeo, little eny.\n",
      "\n",
      "ELoTZt 'tis we of thusew themn cen\n",
      "To with city lives a Edward him:\n",
      "Enliver as my milf seems the subjects, end's,\n",
      "Thou hating be finot mild thy of too keeps of.\n",
      "\n",
      "QUEEN MARGARELLA:\n",
      "That sames onth times process asre will in this ours.\n",
      "\n",
      "Litiz in coury, wilt childy ining!\n",
      "\n",
      "LADOLIO:\n",
      "Is boy asult I have not ho.\n",
      "Bouthing this world general him allows a coursedyYea,\n",
      "Where to do meet though, if cy were by it.\n",
      "\n",
      "ISABLLA:\n",
      "We'll we that be bless-veren that my by thy constrace to him low bear;\n",
      "And love, there to seal'd side with slots.\n",
      "\n",
      "Shat Paris seem in I give uncle, that pluckingh her.\n",
      "\n",
      "Solir eat full bear this wright may not nature, lively, sir hath us doy, see\n",
      "Here it now at decreat thou said me: you wilt\n",
      "wo I honours lives, are you uncread's too some and ury\n",
      "And your wot a he\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx.to(device), max_new_tokens=2000)[0].tolist()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://quantdare.com/wp-content/uploads/2021/11/transformer_arch.png \"Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is one big difference in the architecture in the paper and the network we made - namely, that we made a decoder-only model. Our model takes in the tokens and uses that context to reproduce text that looks like the input text\n",
    "# The original paper was a machine translation paper, where it took a french sentence (\"J'aime manger les pommes\") and translated it into an english sentence (\"I like to eat apples\").\n",
    "# What would happen is the self-attention would first happen on the french sentence, except the upper triangular mask wasn't applied. This would let all the tokens communicate with each other. Then this would create some output embedding, which would then be the input to the decoder. Then, in the multi-head attention in the decoder, there'd be a cross attention, where the query and key would come from the output of the encoder, but the value would come from the decoder.\n",
    "# Note that in the decoder, the multi-head attention would still have that mask.\n",
    "# Anyways, in our example, we don't really have that encoder bit because we're not trying to capture any context from something that's the equivalent of the french sentence. We only are trying to generate Shakespeare, so we only really need the last block_size tokens."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The mathematical trick in self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Consider the following example:\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 2\n",
    "x = torch.randn(B, T, C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want the tokens to communicate, but only with previous tokens\n",
    "# For example, we want the token in the 5th position to only communicate with those in the 1st, 2nd, 3rd, and 4th\n",
    "# What's the simplest way to do this? For now, let's take the average of all the elements that came before it\n",
    "# Granted, this is pretty weak, but let's take the (B, T, C), then for each idx, compute the average channel values for\n",
    "# everything that came before it\n",
    "\n",
    "# Currently using for loops so this is purposely slow\n",
    "xbow = torch.zeros(B, T, C)\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1]\n",
    "        xbow[b, t] = torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.3596, -0.9152],\n",
       "        [ 0.6258,  0.0255],\n",
       "        [ 0.9545,  0.0643],\n",
       "        [ 0.3612,  1.1679],\n",
       "        [-1.3499, -0.5102],\n",
       "        [ 0.2360, -0.2398],\n",
       "        [-0.9211,  1.5433]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.0894, -0.4926],\n",
       "        [ 0.1490, -0.3199],\n",
       "        [ 0.3504, -0.2238],\n",
       "        [ 0.3525,  0.0545],\n",
       "        [ 0.0688, -0.0396],\n",
       "        [ 0.0927, -0.0682],\n",
       "        [-0.0341,  0.1332]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "# Turns out you can make this faster by using matrix multiplication, using lower triangular matrices\n",
    "# Ex:\n",
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0, 10, (3,2)).float()\n",
    "c = a @ b\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To replicate the average quickly, we can do this:\n",
    "weights = torch.tril(torch.ones(T, T))\n",
    "weights = weights / weights.sum(1, keepdim=True)\n",
    "xbow2 = weights @ x # (B, T, T) @ (B, T, C) --> (B, T, C)\n",
    "\n",
    "torch.allclose(xbow, xbow2) # shows they're the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can replicate this with softmax, which is a bit more interesting\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "weights = torch.zeros((T, T))\n",
    "weights = weights.masked_fill(tril == 0, float('-inf'))\n",
    "weights = F.softmax(weights, dim=-1)\n",
    "xbow3 = weights @ x\n",
    "torch.allclose(xbow, xbow3)\n",
    "\n",
    "# The reason we do this is because eventually, we're going to fill that weights matrix with things other than 0\n",
    "# You can think of the weights matrix as representing affinities or relationships between the tokens because\n",
    "# the average is basically weighted by them (via softmax)\n",
    "# Weights set the relationships, the tril will make sure that future tokens can't communicate with previous ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before, we're initializing the weights with all zeros, but we want it to represent the affinities between the different tokens\n",
    "# Every token at each position will have two vectors: a key and a query\n",
    "#   - Query: what am I looking for?\n",
    "#   - Key: what do I contain?\n",
    "# The affinity between two tokens will be the dot product of the key and the query -> that makes up the weights matrix\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 32\n",
    "x = torch.randn(B, T, C)\n",
    "\n",
    "# One head of self-attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "k = key(x) # (B, T, head_size) \"This is what I have\"\n",
    "q = query(x) # (B, T, head_size) \"This is what I want\"\n",
    "\n",
    "weights = q @ k.transpose(-2, -1) # ( B, T, 16) @ (B, 16, T) -> (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "weights = weights.masked_fill(tril == 0, float('-inf'))\n",
    "weights = F.softmax(weights, dim=1)\n",
    "\n",
    "v = value(x) # \"If you find me interesting, here's what I will communicate with you\"\n",
    "out = weights @ v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0248, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0052, 0.0091, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0521, 0.0135, 0.2482, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3171, 0.0214, 0.1642, 0.1188, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0412, 0.0487, 0.1046, 0.0742, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1060, 0.5347, 0.2059, 0.1030, 0.7402, 0.0192, 0.0000, 0.0000],\n",
       "        [0.4298, 0.3409, 0.1769, 0.2027, 0.0480, 0.8472, 0.2329, 0.0000],\n",
       "        [0.0238, 0.0316, 0.1002, 0.5013, 0.0117, 0.1336, 0.7671, 1.0000]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without scaling\n",
      "tensor(1.0449) tensor(1.0700) tensor(17.4690)\n",
      "\n",
      "With scaling\n",
      "tensor(1.0449) tensor(1.0700) tensor(1.0918)\n"
     ]
    }
   ],
   "source": [
    "# NOTES: \n",
    "# Attention is a communication mechanism, can be represented as a directed graph where you're taking the weighted sum of all nodes that point to you --> in this case, you have a special graph where node 1 only points to itself, node 2 is pointed to by node 1 and itself, ...\n",
    "# There isn't a notion of space, so you need to add in the positional encoding\n",
    "# The different examples in the batch don't communicate, only within an example\n",
    "# We implemented a decoder block where we have the mask with the triangular matrix, but you can have an encoder block where you allow future tokens to communicate with past ones -- this is useful for something like sentiment analysis, where you're not predicting a next token (if you want to do this, remove the masked_fill line)\n",
    "# self-attention means keys, queries, values come from the same source (x). Cross attention is when you have some external source where queries come from x, but keys and values can come from some other external source (like an encoder module)\n",
    "# We need to used scaled attention, where you divide weights by sqrt(head_size)\n",
    "\n",
    "k = torch.randn(B, T, head_size)\n",
    "q = torch.randn(B, T, head_size)\n",
    "weights = q @ k.transpose(-2, -1)\n",
    "\n",
    "print(\"Without scaling\")\n",
    "print(k.var(), q.var(), weights.var()) # variation of weights is on the order of head_size, which is bad\n",
    "\n",
    "print(\"\\nWith scaling\")\n",
    "print(k.var(), q.var(), (weights * head_size**-0.5).var()) # if there's 1 variance in k, q, there's 1 variance in weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])\n",
      "tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])\n"
     ]
    }
   ],
   "source": [
    "# Ideally, you want the initialization to be diffuse, if you have super positive and super negative numbers, then the softmax\n",
    "# will converge to one-hot vectors, ex:\n",
    "\n",
    "print(torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]), dim=-1))\n",
    "print(torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]) * 8, dim=-1)) # more like a one-hot at max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt-from-scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
